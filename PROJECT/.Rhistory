qqline(df$enterpriseValue, col = "red")
hist(log(enterpriseValue_shifted),20)
qqnorm(log(enterpriseValue_shifted))
qqline(log(enterpriseValue_shifted), col = "red")
ks.test(log(enterpriseValue_shifted), "pnorm",
mean(log(enterpriseValue_shifted)), sd(log(enterpriseValue_shifted)))
hist(sqrt(enterpriseValue_shifted),20)
qqnorm(sqrt(enterpriseValue_shifted))
qqline(sqrt(enterpriseValue_shifted), col = "red")
ks.test(sqrt(enterpriseValue_shifted),
"pnorm", mean(sqrt(enterpriseValue_shifted)),
sd(sqrt(enterpriseValue_shifted)))
# Chunk 22
#Perform a data shift to avoid negative values
min_value <- min(df$profitMargins)
shift_value <- abs(min_value) + 1
profitMargins_shifted <- df$profitMargins + shift_value
assess_normality_of_transformed_variable(profitMargins_shifted, bins=20)
hist(log(profitMargins_shifted),20)
qqnorm(log(profitMargins_shifted))
qqline(log(profitMargins_shifted), col = "red")
ks.test(log(profitMargins_shifted), "pnorm", mean(log(profitMargins_shifted)), sd(log(profitMargins_shifted)))
hist(sqrt(profitMargins_shifted),20)
qqnorm(sqrt(profitMargins_shifted))
qqline(sqrt(profitMargins_shifted), col = "red")
ks.test(sqrt(profitMargins_shifted), "pnorm", mean(sqrt(profitMargins_shifted)), sd(sqrt(profitMargins_shifted)))
# Chunk 23
#Perform a data shift to avoid negative values
min_value <- min(df$totalCash)
shift_value <- abs(min_value) + 1
totalCash_shifted <- df$totalCash + shift_value
assess_normality_of_transformed_variable(totalCash_shifted, bins=10)
qqnorm(totalCash_shifted)
qqline(totalCash_shifted, col = "red")
# Applying the transformation
lambda <- get_lambda(totalCash_shifted)  # Get optimal lambda
df$totalCash <- boxcox_transform(totalCash_shifted, lambda)
qqnorm(df$totalCash)
qqline(df$totalCash, col = "red")
# Chunk 24
assess_normality_of_transformed_variable(df$totalCashPerShare, bins=10)
qqnorm(df$totalCashPerShare)
qqline(df$totalCashPerShare, col = "red")
# Applying the transformation
lambda <- get_lambda(df$totalCashPerShare)  # Get optimal lambda
df$totalCashPerShare <- boxcox_transform(df$totalCashPerShare, lambda)
qqnorm(df$totalCashPerShare)
qqline(df$totalCashPerShare, col = "red")
# Chunk 25
assess_normality_of_transformed_variable(df$totalDebt, bins=10)
hist(log(df$totalDebt),20)
qqnorm(log(df$totalDebt))
qqline(log(df$totalDebt), col = "red")
ks.test(log(df$totalDebt), "pnorm", mean(log(df$totalDebt)),
sd(log(df$totalDebt)))
hist(sqrt(df$totalDebt),20)
qqnorm(sqrt(df$totalDebt))
qqline(sqrt(df$totalDebt), col = "red")
ks.test(sqrt(df$totalDebt), "pnorm", mean(sqrt(df$totalDebt)),
sd(sqrt(df$totalDebt)))
# Chunk 26
#Perform a data shift to avoid negative values
min_value <- min(df$totalRevenue)
shift_value <- abs(min_value) + 1
totalRevenue_shifted <- df$totalRevenue + shift_value
assess_normality_of_transformed_variable(totalRevenue_shifted, bins=10)
hist(log(totalRevenue_shifted),100)
qqnorm(log(totalRevenue_shifted))
qqline(log(totalRevenue_shifted), col = "red")
ks.test(log(totalRevenue_shifted), "pnorm", mean(log(totalRevenue_shifted)), sd(log(totalRevenue_shifted)))
hist(sqrt(totalRevenue_shifted),20)
qqnorm(sqrt(totalRevenue_shifted))
qqline(sqrt(totalRevenue_shifted), col = "red")
ks.test(sqrt(totalRevenue_shifted), "pnorm", mean(sqrt(totalRevenue_shifted)), sd(sqrt(totalRevenue_shifted)))
# Chunk 27
#Perform a data shift to avoid negative values
min_value <- min(df$revenueGrowth)
shift_value <- abs(min_value) + 1
revenueGrowth_shifted <- df$revenueGrowth + shift_value
assess_normality_of_transformed_variable(revenueGrowth_shifted, bins=10)
hist(log(revenueGrowth_shifted),100)
qqnorm(log(revenueGrowth_shifted))
qqline(log(revenueGrowth_shifted), col = "red")
ks.test(log(revenueGrowth_shifted), "pnorm", mean(log(revenueGrowth_shifted)), sd(log(revenueGrowth_shifted)))
hist(sqrt(revenueGrowth_shifted),20)
qqnorm(sqrt(revenueGrowth_shifted))
qqline(sqrt(revenueGrowth_shifted), col = "red")
ks.test(sqrt(revenueGrowth_shifted), "pnorm", mean(sqrt(revenueGrowth_shifted)), sd(sqrt(revenueGrowth_shifted)))
# Chunk 28
sufficient_states <- names(which(table(df$state) >= 8))
df_filtered <- df[df$state %in% sufficient_states, ]
table(df_filtered$state)
boxM(df_filtered[, numeric_vars], df_filtered$state)
# Boxplots for each numerical variable by 'state'
boxplot(df$marketCap ~ df$state,
main = "Boxplot of marketCap by state",
xlab = "state",
ylab = "marketCap",
col = "red")
boxplot(df$enterpriseValue ~ df$state,
main = "Boxplot of enterpriseValue by state",
xlab = "state",
ylab = "enterpriseValue",
col = "darkred")
boxplot(df$profitMargins ~ df$state,
main = "Boxplot of profitMargins by state",
xlab = "state",
ylab = "profitMargins",
col = "darkgreen")
boxplot(df$totalCash ~ df$state,
main = "Boxplot of totalCash by state",
xlab = "state",
ylab = "totalCash",
col = "purple")
boxplot(df$totalCashPerShare ~ df$state,
main = "Boxplot of totalCashPerShare by state",
xlab = "state",
ylab = "totalCashPerShare",
col = "pink")
boxplot(df$totalDebt ~ df$state,
main = "Boxplot of totalDebt by state",
xlab = "state",
ylab = "totalDebt",
col = "lightpink")
boxplot(df$totalRevenue ~ df$state,
main = "Boxplot of totalRevenue by state",
xlab = "state",
ylab = "totalRevenue",
col = "black")
boxplot(df$revenueGrowth ~ df$state,
main = "Boxplot of revenueGrowth by state",
xlab = "state",
ylab = "revenueGrowth",
col = "brown")
# Chunk 29
table(df$sector)
boxM(df[, numeric_vars], df$sector)
# Boxplots for each numerical variable by 'sector'
boxplot(df$marketCap ~ df$sector,
main = "Boxplot of marketCap by sector",
xlab = "sector",
ylab = "marketCap",
col = "red", las=2)
boxplot(df$enterpriseValue ~ df$sector,
main = "Boxplot of enterpriseValue by sector",
xlab = "state",
ylab = "enterpriseValue",
col = "darkred", las=2)
boxplot(df$profitMargins ~ df$sector,
main = "Boxplot of profitMargins by sector",
xlab = "sector",
ylab = "profitMargins",
col = "darkgreen", las=2)
boxplot(df$totalCash ~ df$sector,
main = "Boxplot of totalCash by sector",
xlab = "sector",
ylab = "totalCash",
col = "purple", las=2)
boxplot(df$totalCashPerShare ~ df$sector,
main = "Boxplot of totalCashPerShare by sector",
xlab = "sector",
ylab = "totalCashPerShare",
col = "pink", las=2)
boxplot(df$totalDebt ~ df$sector,
main = "Boxplot of totalDebt by sector",
xlab = "sector",
ylab = "totalDebt",
col = "lightpink", las=2)
boxplot(df$totalRevenue ~ df$sector,
main = "Boxplot of totalRevenue by sector",
xlab = "sector",
ylab = "totalRevenue",
col = "black", las=2)
boxplot(df$revenueGrowth ~ df$sector,
main = "Boxplot of revenueGrowth by sector",
xlab = "sector",
ylab = "revenueGrowth",
col = "brown", las=2)
# Chunk 30
table(df$recommendationKey)
boxM(df[, numeric_vars], df$recommendationKey)
# Boxplots for each numerical variable by 'recommendationKey'
boxplot(df$marketCap ~ df$recommendationKey,
main = "Boxplot of marketCap by recommendationKey",
xlab = "recommendationKey",
ylab = "marketCap",
col = "red")
boxplot(df$enterpriseValue ~ df$recommendationKey,
main = "Boxplot of enterpriseValue by recommendationKey",
xlab = "recommendationKey",
ylab = "enterpriseValue",
col = "pink")
boxplot(df$profitMargins ~ df$recommendationKey,
main = "Boxplot of profitMargins by recommendationKey",
xlab = "recommendationKey",
ylab = "profitMargins",
col = "purple")
boxplot(df$totalCash ~ df$recommendationKey,
main = "Boxplot of totalCash by recommendationKey",
xlab = "recommendationKey",
ylab = "totalCash",
col = "lightpink")
boxplot(df$totalCashPerShare ~ df$recommendationKey,
main = "Boxplot of totalCashPerShare by recommendationKey",
xlab = "recommendationKey",
ylab = "totalCashPerShare",
col = "black")
boxplot(df$totalDebt ~ df$recommendationKey,
main = "Boxplot of totalDebt by recommendationKey",
xlab = "recommendationKey",
ylab = "totalDebt",
col = "darkgreen")
boxplot(df$totalRevenue ~ df$recommendationKey,
main = "Boxplot of totalRevenue by recommendationKey",
xlab = "recommendationKey",
ylab = "totalRevenue",
col = "darkred")
boxplot(df$revenueGrowth ~ df$recommendationKey,
main = "Boxplot of revenueGrowth by recommendationKey",
xlab = "recommendationKey",
ylab = "revenueGrowth",
col = "darkblue")
# Chunk 31
rownames(df) <- 1:nrow(df)
pca_res <- PCA(df, scale.unit=T, graph=T,
quali.sup=which(names(df) %in% c("shortName", "state", "sector", "recommendationKey")),
)
eigens <- pca_res$eig; eigens
pca_res$var$contrib
# comp1: 4.01 # comp2: 1.222
#Plot a scree plot
plot(pca_res$eig[,2], type="o",
main="Scree Plot: Percentage of Variance by Component",
xlab="Number of components", ylab="Percentage of variance",
col="blue", pch=16, xaxt="n", yaxt="n")
axis(1, at=1:length(pca_res$eig[,2]), labels=1:length(pca_res$eig[,2]), las=1)
axis(2, las=1)
# Interpretation of hte leadings/correlations of variables at each dimension
pca_res$var$coord[, 1:3]
# dim 1 vs dim 2
fviz_pca_biplot(
pca_res,
axes = c(1,2),
label = "var",
# habillage = df$sector,
# addEllipses = TRUE,
pointsize = 1,
repel = TRUE            # Avoid overlapping labels
)
plot.PCA(pca_res, choix = "ind", label = "ind", axes = c(1, 2))
## FACTOR ANALYSIS
# Chunk 32
###### Bartlett's Test of Spherecity####
# bartlett test to check if the variables are correlated
bart_spher(df[,c(4:6,8:12)]) # p_value = 2.23e-16 --> they are correlated
###### Kaiser-Meyer-Olkin (KMO) Test ###
kmo <- function(x)
{
x <- subset(x, complete.cases(x))   # Omit missing values
r <- cor(x)                         # Correlation matrix
r2 <- r^2                           # Squared correlation coefficients
i <- solve(r)                       # Inverse matrix of correlation matrix
d <- diag(i)                        # Diagonal elements of inverse matrix
p2 <- (-i/sqrt(outer(d, d)))^2      # Squared partial correlation coefficients
diag(r2) <- diag(p2) <- 0           # Delete diagonal elements
KMO <- sum(r2)/(sum(r2)+sum(p2))
MSA <- colSums(r2)/(colSums(r2)+colSums(p2))
return(list(KMO=KMO, MSA=MSA))
}
#KMO index
kmo(df[,c(4:6,8:12)])
#$KMO
#[1] 0.794
# KMO index shows that the data is factorable.
#factor analysis
fa_res <- fa(df[,c(4:6,9:12)], nfactors = 4, rotate="varimax")
fa_res
fa.diagram(fa_res)
# Chunk 33
# Prepare numerical data
num_df <- df[, numeric_vars]
rownames(num_df) <- df$shortName
# Compute Euclidean distance and MDS
dist_euc <- dist(num_df, method = "euclidean")
mds_num <- cmdscale(dist_euc, eig = TRUE)
# Perform k-means clustering (2 clusters)
kmeans_result_num <- kmeans(mds_num$points, centers = 2)
num_df$cluster <- as.factor(kmeans_result_num$cluster)
# Scree Plot for Euclidean distance
distance_preserved_num <- mds_num$eig / sum(abs(mds_num$eig)) * 100
barplot(distance_preserved_num[1:limit],
main = "Scree Plot (Euclidean distance)",
xlab = "Dimension",
ylab = "Percentage of distance preserved",
col = rainbow(limit))
# MDS Plot with clusters
cluster_colors <- setNames(rainbow(length(unique(num_df$cluster))), levels(num_df$cluster))
plot(mds_num$points[, 1], mds_num$points[, 2],
col = cluster_colors[kmeans_result_num$cluster], pch = 19, cex = 0.7,
main = "MDS Plot (Euclidean distance with Clusters)",
xlab = sprintf("First Dimension (%.2f%%)", distance_preserved_num[1]),
ylab = sprintf("Second Dimension (%.2f%%)", distance_preserved_num[2]))
text(mds_num$points[, 1], mds_num$points[, 2],
labels = rownames(num_df), cex = 0.6, pos = 4, col = cluster_colors[kmeans_result_num$cluster])
# Profiling clusters
catdes(num_df, proba = 0.05, num.var = ncol(num_df))
# Chunk 34
# Prepare data
summary(df)
num_vars <- c("marketCap", "enterpriseValue", "profitMargins", "totalCash", "totalCashPerShare", "totalDebt", "totalRevenue", "revenueGrowth")
categ_df <- df[, c(num_vars, "sector", "recommendationKey")]
rownames(categ_df) <- df$shortName
# Compute Gower distance and MDS
dist_gow <- daisy(categ_df, metric = "gower")
mds_mix <- cmdscale(dist_gow, eig = TRUE)
# Perform k-means clustering (3 clusters)
kmeans_result <- kmeans(mds_mix$points, centers = 3)
table(kmeans_result$cluster)
table(categ_df$cluster)
categ_df$cluster <- as.factor(kmeans_result$cluster)
# Scree Plot
distance_preserved <- mds_mix$eig / sum(abs(mds_mix$eig)) * 100; distance_preserved[1] + distance_preserved[2]
barplot(distance_preserved[1:limit],
main = "Scree Plot (Gower distance)",
xlab = "Dimension",
ylab = "Percentage of distance preserved",
col = rainbow(limit))
# MDS Plot with clusters
cluster_colors <- setNames(rainbow(length(unique(categ_df$cluster))), levels(categ_df$cluster))
plot(mds_mix$points[, 1], mds_mix$points[, 2],
col = cluster_colors[categ_df$cluster], pch = 19, cex = 0.7,
main = "MDS Plot (Gower distance with Clusters)",
xlab = sprintf("First Dimension (%.2f%%)", distance_preserved[1]),
ylab = sprintf("Second Dimension (%.2f%%)", distance_preserved[2]))
text(mds_mix$points[, 1], mds_mix$points[, 2],
labels = rownames(categ_df), cex = 0.6, pos = 4, col = cluster_colors[categ_df$cluster])
# Profiling clusters
catdes(categ_df, proba = 0.05, num.var = ncol(categ_df))
# Chunk 35
contingency_table <- table(df$sector, df$recommendationKey); contingency_table
res_ca <- CA(contingency_table)
# 1. Scree Plot (Eigenvalues)
cumulative_inertia <- cumsum(res_ca$eig[, 2])
avg_eigen <- mean(res_ca$eig[, 1])
# Eigenvalues and Cumulative variance
par(mfrow = c(1, 2))  # Split plotting window for two plots
plot(res_ca$eig[, 2], type = "b", pch = 16, lwd = 2,
xlab = "Dimensions", ylab = "Percentage of Variance",
main = "Variance explained", col = "blue")
plot(res_ca$eig[, 1], type = "b", pch = 16, lwd = 2,
xlab = "Dimensions", ylab = "Eigenvalue",
main = "Average eigenvalue comparison", col = "purple")
abline(h = avg_eigen, col = "red", lty = 2)  # Average eigenvalue threshold
# Plot row categories (sectors)
fviz_ca_row(res_ca, repel = TRUE, col.row = "contrib",
gradient.cols = c("blue", "green", "red"),
title = "CA - Row Categories (Companies/Sectors)")
# Plot column categories (recommendations)
fviz_ca_col(res_ca, repel = TRUE, col.col = "contrib",
gradient.cols = c("blue", "green", "red"),
title = "CA - Column Categories (Recommendation Keys)")
# Both profiles together
fviz_ca_biplot(res_ca, repel = TRUE, col.row = "contrib",
col.col = "contrib", gradient.cols = c("blue", "green", "red"),
title = "CA - Biplot", labelsize=8)
# Chunk 36
?HCPC
res.hcpc <- HCPC(pca_res, min=2,nb.clust=-1, graph=TRUE)
nb.clust <- res.hcpc$call$t$nb.clust
res.hcpc$call$t
res.hcpc$desc.var
# Visualisation of clusters
fviz_dend(res.hcpc, k = nb.clust, rect = TRUE, rect_fill = TRUE)
fviz_cluster(res.hcpc, repel = TRUE, show.clust.cent = TRUE,
main = "Factor map", ggtheme= theme_minimal())
plot(res.hcpc, choice = "3D.map")
#take extreme examples of the clusters
df[610, 1]
df[609, 1]
df[502, 1]
df[7, 1]
df[63, 1]
df[254, 1]
# Chunk 37
# Ensure the dataset is balanced on the predicted variable:
ll <- which(df$recommendationKey=="strong_buy" |
df$recommendationKey=="underperform")
length(ll)
df<-df[-ll,]
table(df$recommendationKey)
df <- df %>%
mutate(recommendationKey = case_when(
recommendationKey == "strong_buy" ~ "buy",      # Change "strong buy" to "buy"
recommendationKey == "underperform" ~ "none",  # Change "underperform" to "none"
TRUE ~ recommendationKey                        # Leave other values unchanged
))
table(df$recommendationKey)
##################################################
##optional -> Balance the dataset.################
# Separate the data by class
buy_data <- df %>% filter(recommendationKey == "buy")
hold_data <- df %>% filter(recommendationKey == "hold")
none_data <- df %>% filter(recommendationKey == "none")
# Get the minimum class size
min_class_size <- min(nrow(buy_data), nrow(hold_data), nrow(none_data))
# Undersample the majority classes
buy_data_undersampled <- sample_n(buy_data, min_class_size)
hold_data_undersampled <- sample_n(hold_data, min_class_size)
none_data_undersampled <- sample_n(none_data, min_class_size)
# Combine the undersampled data
df <- bind_rows(buy_data_undersampled, hold_data_undersampled, none_data_undersampled)
# Check the class distribution after undersampling
table(df$recommendationKey)
##################################################
#split data in training and test set
set.seed(123)
training.samples <- df$recommendationKey %>% createDataPartition(p = 0.8, list = FALSE)
train.data <- df[training.samples, ]
test.data <- df[-training.samples, ]
# Standardize the data. Categorical variables are automatically ignored.
# Estimate preprocessing parameters
preproc.param <- train.data %>%
preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)
# Chunk 38
###########################################
# Use stepwise to keep relevant variables #
###########################################
predictors <- train.transformed[, c("marketCap", "enterpriseValue", "profitMargins",
"totalCash", "totalCashPerShare", "totalDebt",
"totalRevenue", "revenueGrowth")]
response <- train.transformed$recommendationKey
# Perform Stepwise QDA Classification with backward selection and CR criterion
stepwise_qda <- stepclass(predictors, response, method="qda",
direction="backward", criterion="CR")
print(stepwise_qda)
############################################
#   Create model with seldected variables  #
############################################
data2 <- train.transformed[, c("marketCap" , "profitMargins" , "totalCash" , "totalCashPerShare" ,
"totalDebt" , "totalRevenue", "recommendationKey")]
data3 <- train.transformed[, c("marketCap" , "enterpriseValue" , "profitMargins" , "totalDebt" ,
"totalRevenue" , "recommendationKey")]
QDA <- qda(recommendationKey~., data = data3)
QDA
# Make predictions
predictions <- QDA %>% predict(test.transformed)
mean(predictions$class == test.transformed$recommendationKey)
#Contingency Table of Observed and Predicted Values
# Contingency Table of Observed and Predicted Values
tab <- table(Observed = test.transformed$recommendationKey, Predicted = predictions$class)
# Print the contingency table
print(tab)
#CCR across groups (over rows)
diag(prop.table(tab, 1))
# Chunk 39
#########################################
#       try LDA with same vars.         #
#########################################
#check var.homogeneity
# Boxplot for totalCash by recommendationKey
ggplot(df, aes(x = recommendationKey, y = totalCash, fill = recommendationKey)) +
geom_boxplot() +
labs(title = "Boxplot of totalCash by recommendationKey",
x = "Recommendation Key", y = "Total Cash") +
theme_minimal()
ggplot(df, aes(x = recommendationKey, y = totalCashPerShare, fill = recommendationKey)) +
geom_boxplot() +
labs(title = "Boxplot of totalCashPerShare by recommendationKey",
x = "Recommendation Key", y = "Total Cash Per Share") +
theme_minimal()
data <- train.transformed[, c("totalCash", "totalCashPerShare", "recommendationKey")]
databalancedDF <- train.transformed[, c("marketCap" , "profitMargins" , "totalCash" , "totalCashPerShare" ,
"totalDebt" , "totalRevenue", "recommendationKey")]
modelLDA <- lda(recommendationKey~., data = data)
modelLDA
# Make predictions
predictionLDAs <- modelLDA %>% predict(test.transformed)
mean(predictionLDAs$class == test.transformed$recommendationKey)
#Contingency Table of Observed and Predicted Values
tab<-table(test.transformed$recommendationKey,predictionLDAs$class)
tab
#Correct Classification Rate (CCR)
classrate<-sum(diag(tab))/sum(tab)
classrate
# Total CCR (alternative way)
sum(diag(prop.table(tab)))
#CCR across groups (over rows)
diag(prop.table(tab, 1))
#Prediction Accuracy p1^2+p^2
pa<-modelLDA$prior[1]^2 + modelLDA$prior[2]^2
pa
### Plot of lda results
plot(modelLDA)
# Chunk 40
n <- length(test.transformed);n
k<- 3
#correctly classified observations:
correct <- sum(diag(tab));correct
Qstat <- (n-correct*k)^2/n*(k-1);Qstat
alpha <- 0.01  # Significance level
chi_critical <- qchisq(1 - alpha, df = k - 1)
cat("Q statistic:", Qstat, "\n")
cat("Critical value of Chi-squared:", chi_critical, "\n")
# Hypothesis Test
if (Qstat > chi_critical) {
cat("Reject the null hypothesis: The discriminant function is important.\n")
} else {
cat("Fail to reject the null hypothesis: The discriminant function is not important.\n")
}
